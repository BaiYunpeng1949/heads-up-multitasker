{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec82b95b",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d328b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "import itertools\n",
    "import csv\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import anderson_ksamp\n",
    "from ast import literal_eval\n",
    "\n",
    "# Get data source\n",
    "data_dir = 'data_process/12-06/'\n",
    "\n",
    "# Read raw simulated data\n",
    "simulated_raw_data = data_dir + '12-06-08-45-simulated_data_aa_wsr_rsr.csv'\n",
    "# Read Human Data\n",
    "human_data = data_dir + 'human_data_aa_wsr_rsr.csv'\n",
    "\n",
    "# Convert to a dataframe\n",
    "df_raw_sim = pd.read_csv(simulated_raw_data)\n",
    "df_human = pd.read_csv(human_data)\n",
    "\n",
    "# Identify the parameters that to be tuned later\n",
    "WEIGHTS = 'weights'             # Ranges from 0-1\n",
    "WALK_FACTORS = 'walk_factors'   # Ranges from 0-1\n",
    "SIGN_FACTORS = 'sign_factors'   # Ranges from 0-1\n",
    "# params = {\n",
    "#     WEIGHT: None,\n",
    "#     WALK_FACTOR: None,\n",
    "#     SIGN_FACTOR: None,\n",
    "# }\n",
    "# Some other variables from the simulated file\n",
    "STEPS = 'steps'\n",
    "SIGN_READ = 'sign_read'\n",
    "STEP_WISE_WALKING_POSITIONS = 'step_wise_walking_positions'\n",
    "EXP_WALKING_POSITIONS = 'walking_positions'\n",
    "STEP_WISE_WALKING_SPEEDS = 'step_wise_walking_speeds'\n",
    "EXP_WALKING_SPEEDS = 'walking_speeds'\n",
    "WALKING_SPEED_RATIOS = 'walking_speed_ratios'\n",
    "STEP_WISE_ATTENTIONS = 'step_wise_attentions'\n",
    "EXP_ATTENTION = 'attention_allocation'\n",
    "ATTENTION_ON_SIGN = 'attention_on_sign'\n",
    "ATTENTION_ON_OHMD = 'attention_on_ohmd'\n",
    "SIGN_POSITIONS = 'sign_positions'\n",
    "STEP_WISE_READING_RATIOS = 'step_wise_reading_ratios'\n",
    "READING_SPEED_RATIOS = 'reading_speed_ratios'\n",
    "EXP_READING_RATIOS = 'reading_ratios'\n",
    "RECTANGLE_PATH_LENGTH = 'rectangle_path_length'\n",
    "EP_LEN = 'ep_len'\n",
    "\n",
    "SIGN = 'Sign'\n",
    "ZERO_DOT_ONE = 0.1\n",
    "WALK_FACTORS = 'walk_factors'\n",
    "PERCEPTION_FACTORS = 'perception_factors'\n",
    "\n",
    "# Determine the metrics\n",
    "ATTENTION_ALLOCATION = 'attention_allocation'\n",
    "WALKING_SPEED_RATIO = 'walking_speed_ratio'\n",
    "READING_SPEED_RATIO = 'reading_speed_ratio'\n",
    "metrics = [ATTENTION_ALLOCATION, WALKING_SPEED_RATIO, READING_SPEED_RATIO]\n",
    "\n",
    "# Parameters that can be pre-defined\n",
    "DEFAULT_WALK_FACTOR = 0.5\n",
    "DEFAULT_SIGN_FACTOR = 0.5\n",
    "\n",
    "# Number of signs in the experiment\n",
    "NUM_SIGN_IN_EXP = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb694665",
   "metadata": {},
   "source": [
    "### Process the Raw Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b7992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string representations of lists into actual lists\n",
    "def literal_eval_col(col):\n",
    "    return col.apply(literal_eval)\n",
    "# def literal_eval_col(col):\n",
    "#     return col.apply(lambda x: literal_eval(x) if not pd.isnull(x) else [])\n",
    "\n",
    "# Round values\n",
    "def round_nested_lists(column):\n",
    "    rounded_column = []\n",
    "    for row in column:\n",
    "        if isinstance(row, list):\n",
    "            rounded_row = [round(element, 1) if isinstance(element, float) else element for element in row]\n",
    "            rounded_column.append(rounded_row)\n",
    "        else:\n",
    "            rounded_column.append(row)\n",
    "    return rounded_column\n",
    "\n",
    "# Process raw simulated data - main function - process data line by line\n",
    "def process_raw_simulated_data(df_raw_sim):\n",
    "    # Convert strings to lists in the whole df\n",
    "    df_raw_sim.dropna(how='all', inplace=True)\n",
    "    \n",
    "    df_raw_sim[STEP_WISE_WALKING_POSITIONS] = literal_eval_col(df_raw_sim[STEP_WISE_WALKING_POSITIONS])\n",
    "    df_raw_sim[STEP_WISE_WALKING_SPEEDS] = literal_eval_col(df_raw_sim[STEP_WISE_WALKING_SPEEDS])\n",
    "    df_raw_sim[STEP_WISE_ATTENTIONS] = literal_eval_col(df_raw_sim[STEP_WISE_ATTENTIONS])\n",
    "    df_raw_sim[SIGN_READ] = literal_eval_col(df_raw_sim[SIGN_READ])\n",
    "    df_raw_sim[STEP_WISE_READING_RATIOS] = literal_eval_col(df_raw_sim[STEP_WISE_READING_RATIOS])\n",
    "    rectangle_path_length = df_raw_sim.at[1, 'rectangle_path_length']\n",
    "    \n",
    "    #####################################################################\n",
    "    # Get rid of the rows whose len(sign_read) < num_sign_in_exp\n",
    "    df_read_eight_signs = df_raw_sim[df_raw_sim[SIGN_READ].apply(lambda x: len(x) >= NUM_SIGN_IN_EXP)]\n",
    "#     df_read_eight_signs = df_read_eight_signs[df_read_eight_signs[WALK_FACTORS] == DEFAULT_WALK_FACTOR]\n",
    "    \n",
    "    #####################################################################\n",
    "    empty_lists = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    \n",
    "    # Creating a new column initialized with empty lists\n",
    "    df_read_eight_signs[EXP_ATTENTION] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    df_read_eight_signs[EXP_WALKING_SPEEDS] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    df_read_eight_signs[EXP_READING_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    # Iterate over each row\n",
    "    for index, row in df_read_eight_signs.iterrows():\n",
    "        # Find the index where the value in 'step_wise_walking_positions' first exceeds 60\n",
    "        index_exceeding_60 = next((i for i, val in enumerate(row[STEP_WISE_WALKING_POSITIONS]) if val > rectangle_path_length), None)\n",
    "        \n",
    "        # If such an index is found, slice 'step_wise_attention_allocation' up to that index\n",
    "        if index_exceeding_60 is not None:\n",
    "            df_read_eight_signs.at[index, EXP_ATTENTION] = row[STEP_WISE_ATTENTIONS][:index_exceeding_60]\n",
    "            df_read_eight_signs.at[index, EXP_WALKING_SPEEDS] = row[STEP_WISE_WALKING_SPEEDS][:index_exceeding_60]\n",
    "            df_read_eight_signs.at[index, EXP_READING_RATIOS] = row[STEP_WISE_READING_RATIOS][:index_exceeding_60]\n",
    "        else:\n",
    "            # If no value exceeds 60, the column remains an empty list for this row\n",
    "            df_read_eight_signs.at[index, EXP_ATTENTION] = []\n",
    "            df_read_eight_signs.at[index, EXP_WALKING_SPEEDS] = []\n",
    "            df_read_eight_signs.at[index, EXP_READING_RATIOS] = []\n",
    "    \n",
    "    #####################################################################\n",
    "    # Get indexes where the attention is on the sign, which are on the OHMD\n",
    "    # Initialize the new columns with empty lists\n",
    "    df_read_eight_signs[ATTENTION_ON_SIGN] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    df_read_eight_signs[ATTENTION_ON_OHMD] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    # Initialize the new column with empty lists\n",
    "    df_read_eight_signs[READING_SPEED_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    # Iterate over each row\n",
    "    for index, row in df_read_eight_signs.iterrows():\n",
    "        # Lists to store attention data\n",
    "        attention_on_sign = []\n",
    "        attention_on_ohmd = []\n",
    "        reading_speed_ratios = []\n",
    "\n",
    "        # Check each item in the 'EXP_ATTENTION' list\n",
    "        for i, attention_item in enumerate(row[EXP_ATTENTION]):\n",
    "            if attention_item != 'Sign':\n",
    "                attention_on_ohmd.append(attention_item)\n",
    "                # Append the corresponding item from 'EXP_READING_RATIOS'\n",
    "                reading_speed_ratios.append(row[EXP_READING_RATIOS][i])\n",
    "            else:\n",
    "                attention_on_sign.append(attention_item)         \n",
    "\n",
    "        # Assign the lists to the new columns\n",
    "        df_read_eight_signs.at[index, ATTENTION_ON_SIGN] = attention_on_sign\n",
    "        df_read_eight_signs.at[index, ATTENTION_ON_OHMD] = attention_on_ohmd\n",
    "        df_read_eight_signs.at[index, READING_SPEED_RATIOS] = reading_speed_ratios\n",
    "        \n",
    "    #####################################################################\n",
    "    df_read_eight_signs[WALKING_SPEED_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    # Iterate over each row\n",
    "    for index, row in df_read_eight_signs.iterrows():\n",
    "        # Filter walking speeds greater than 0.1\n",
    "        walking_speeds_above_threshold = [speed for speed in row[EXP_WALKING_SPEEDS] if speed > ZERO_DOT_ONE]\n",
    "        # Assign the filtered speeds to the new column\n",
    "        df_read_eight_signs.at[index, WALKING_SPEED_RATIOS] = walking_speeds_above_threshold\n",
    "    \n",
    "    #####################################################################\n",
    "    df_read_eight_signs[ATTENTION_ALLOCATION] = 0\n",
    "    df_read_eight_signs[WALKING_SPEED_RATIO] = 0\n",
    "    df_read_eight_signs[READING_SPEED_RATIO] = 0\n",
    "    \n",
    "    # Iterate over each row to calculate the ratios\n",
    "    for index, row in df_read_eight_signs.iterrows():\n",
    "        # Calculate the attention allocation ratio\n",
    "        if len(row[ATTENTION_ON_OHMD]) > 0:\n",
    "            df_read_eight_signs.at[index, ATTENTION_ALLOCATION] = len(row[ATTENTION_ON_SIGN]) / (len(row[ATTENTION_ON_OHMD]) + len(row[ATTENTION_ON_SIGN]))\n",
    "        else:\n",
    "            df_read_eight_signs.at[index, ATTENTION_ALLOCATION] = float('inf')  # or some other value to indicate undefined\n",
    "\n",
    "        # Calculate the walking speed ratio (average)\n",
    "        if row[WALKING_SPEED_RATIOS]:\n",
    "            df_read_eight_signs.at[index, WALKING_SPEED_RATIO] = sum(row[WALKING_SPEED_RATIOS]) / len(row[WALKING_SPEED_RATIOS])\n",
    "\n",
    "        # Calculate the reading speed ratio (average)\n",
    "        if row[READING_SPEED_RATIOS]:\n",
    "            df_read_eight_signs.at[index, READING_SPEED_RATIO] = sum(row[READING_SPEED_RATIOS]) / len(row[READING_SPEED_RATIOS])\n",
    "        \n",
    "    #####################################################################\n",
    "    # Write the DataFrame to a CSV file\n",
    "    df_read_eight_signs.to_csv(data_dir+'processed_1206_simulated_data.csv', index=False)\n",
    "    \n",
    "    return df_read_eight_signs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7194f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\3547267147.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[EXP_ATTENTION] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\3547267147.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[EXP_WALKING_SPEEDS] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\3547267147.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[EXP_READING_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\3547267147.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[ATTENTION_ON_SIGN] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\3547267147.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[ATTENTION_ON_OHMD] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\3547267147.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[READING_SPEED_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\3547267147.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[WALKING_SPEED_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\3547267147.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[ATTENTION_ALLOCATION] = 0\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\3547267147.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[WALKING_SPEED_RATIO] = 0\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\3547267147.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[READING_SPEED_RATIO] = 0\n"
     ]
    }
   ],
   "source": [
    "df_sim_after_raw_process = process_raw_simulated_data(df_raw_sim=df_raw_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12fd737",
   "metadata": {},
   "source": [
    "### Parameter Inference: Attention Allocation (s), Walking Speed Ratio (%), Reading Speed Ratio (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec0c9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize a list\n",
    "def normalize(lst):\n",
    "    min_val = min(lst)\n",
    "    max_val = max(lst)\n",
    "    if min_val == max_val:  # Avoid division by zero\n",
    "        return [0.5 for _ in lst]  # Return 0.5 (middle) if all values are same\n",
    "    return [(x - min_val) / (max_val - min_val) for x in lst]\n",
    "\n",
    "# Define the cost function\n",
    "def compute_cost(sim_data, human_data):\n",
    "#     return sum(abs(sim - human) for sim, human in zip(sim_data, human_data))\n",
    "    return abs(sim_data - human_data)\n",
    "\n",
    "# Find the best parameter\n",
    "def find_best_params(df_sim, mean_train_aa, mean_train_wsr, mean_train_rsr):\n",
    "#     # Filter by adding constraints\n",
    "#     df_sim = df_sim[df_sim['xxxx'] == xxxx]\n",
    "    \n",
    "    unique_params = df_sim[[WEIGHTS, WALK_FACTORS, PERCEPTION_FACTORS]].drop_duplicates()\n",
    "    min_cost = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    for index, row in unique_params.iterrows():\n",
    "        filtered_df = df_sim[\n",
    "            (df_sim[WEIGHTS] == row[WEIGHTS]) &\n",
    "            (df_sim[WALK_FACTORS] == row[WALK_FACTORS]) &\n",
    "            (df_sim[PERCEPTION_FACTORS] == row[PERCEPTION_FACTORS])\n",
    "        ]\n",
    "        \n",
    "        # Get simulated data\n",
    "        sim_aa = filtered_df[ATTENTION_ALLOCATION].values[0]\n",
    "        sim_wsr = filtered_df[WALKING_SPEED_RATIO].values[0]\n",
    "        sim_rsr = filtered_df[READING_SPEED_RATIO].values[0]\n",
    "        \n",
    "        # Get human data\n",
    "        human_aa = mean_train_aa\n",
    "        human_wsr = mean_train_wsr\n",
    "        human_rsr = mean_train_rsr\n",
    "        \n",
    "        # Compute the cost\n",
    "        cost_aa = compute_cost(sim_aa, human_aa)\n",
    "        cost_wsr = compute_cost(sim_wsr, human_wsr)\n",
    "        cost_rsr = compute_cost(sim_rsr, human_rsr)\n",
    "        \n",
    "        total_cost = cost_aa + cost_wsr + cost_rsr\n",
    "\n",
    "        if total_cost < min_cost:\n",
    "            min_cost = total_cost\n",
    "            best_params = row\n",
    "    \n",
    "    # Given the best parameters and the dataframe, return the simulated results\n",
    "    sim_aa_best = []\n",
    "    sim_wsr_best = []\n",
    "    sim_rsr_best = []\n",
    "    \n",
    "    # Extract the simulated steps and error for each layout based on best_params\n",
    "    filtered_df = df_sim[\n",
    "        (df_sim[WEIGHTS] == best_params[WEIGHTS]) &\n",
    "        (df_sim[WALK_FACTORS] == best_params[WALK_FACTORS]) &\n",
    "        (df_sim[PERCEPTION_FACTORS] == best_params[PERCEPTION_FACTORS])\n",
    "    ]\n",
    "\n",
    "    sim_aa_best.append(filtered_df[ATTENTION_ALLOCATION].values[0])\n",
    "    sim_wsr_best.append(filtered_df[WALKING_SPEED_RATIO].values[0])\n",
    "    sim_rsr_best.append(filtered_df[READING_SPEED_RATIO].values[0])\n",
    "\n",
    "    return best_params, min_cost, sim_aa_best, sim_wsr_best, sim_rsr_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ded1923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 31s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_iterations = 500\n",
    "all_costs = []\n",
    "all_best_params = []\n",
    "\n",
    "# # Lists to store sim-to-real mapping ratios for each iteration\n",
    "# sim_to_real_ratios_duration = []\n",
    "# sim_to_real_ratios_error = []\n",
    "\n",
    "sim_aas = []\n",
    "sim_wsrs = []\n",
    "sim_rsrs = []\n",
    "human_train_aas = []\n",
    "human_train_wsrs = []\n",
    "human_train_rsrs = []\n",
    "human_test_aas = []\n",
    "human_test_wsrs = []\n",
    "human_test_rsrs = []\n",
    "human_train_aas_details = []\n",
    "human_train_wsrs_details = []\n",
    "human_train_rsrs_details = []\n",
    "human_test_aas_details = []\n",
    "human_test_wsrs_details = []\n",
    "human_test_rsrs_details = []\n",
    "\n",
    "# Get human data from the dataframe\n",
    "df_human_aa = df_human[ATTENTION_ALLOCATION]\n",
    "df_human_wsr = df_human[WALKING_SPEED_RATIO]\n",
    "df_human_rsr = df_human[READING_SPEED_RATIO]\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Number of participants\n",
    "#     num_participants = len(human_duration_data[0])\n",
    "    num_participants = len(df_human)\n",
    "\n",
    "    # Generate list of indices based on participants\n",
    "    indices = list(range(num_participants))\n",
    "\n",
    "    # Split indices to ensure consistency\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=0.5, random_state=i)  \n",
    "    # using i as the seed for reproducibility\n",
    "\n",
    "    # Use these indices to split the human data consistently across participants\n",
    "    def split_data_based_on_indices(data, train_indices, test_indices):\n",
    "        train_set = [data[i] for i in train_indices]\n",
    "        test_set = [data[i] for i in test_indices]\n",
    "        return train_set, test_set\n",
    "\n",
    "    # Split human aa data\n",
    "    train_aas, test_aas = split_data_based_on_indices(df_human_aa, train_indices, test_indices)\n",
    "\n",
    "    # Split human wsr data\n",
    "    train_wsrs, test_wsrs = split_data_based_on_indices(df_human_wsr, train_indices, test_indices)\n",
    "    \n",
    "    # Split human rsr data\n",
    "    train_rsrs, test_rsrs = split_data_based_on_indices(df_human_rsr, train_indices, test_indices)\n",
    "\n",
    "    # Compute mean for the training and test sets\n",
    "    mean_train_aa = np.mean(train_aas)\n",
    "    mean_train_wsr = np.mean(train_wsrs)\n",
    "    mean_train_rsr = np.mean(train_rsrs)\n",
    "    mean_test_aa = np.mean(test_aas)\n",
    "    mean_test_wsr = np.mean(test_wsrs)\n",
    "    mean_test_rsr = np.mean(test_rsrs)\n",
    "\n",
    "    # Using the function to find the best parameters\n",
    "    best_params, _, sim_best_aas, sim_best_wsrs, sim_best_rsrs = find_best_params(df_sim_after_raw_process, mean_train_aa, mean_train_wsr, mean_train_wsr)\n",
    "    all_best_params.append(best_params)\n",
    "    \n",
    "#     # Get sim to real mapping ratios for duration and error metrics respectively\n",
    "#     # Compute sim-to-real ratio for the current iteration\n",
    "#     sim_to_real_ratio_duration = sum(mean_train_duration) / sum(sim_durations)\n",
    "#     sim_to_real_ratio_error = sum(mean_train_error) / sum(sim_errors)\n",
    "    \n",
    "    # Store the computed ratios\n",
    "    for sim_best_aa, sim_best_wsr, sim_best_rsr, test_aa, test_wsr, test_rsr, train_aa, train_wsr, train_rsr in zip(\n",
    "        sim_best_aas, \n",
    "        sim_best_wsrs,\n",
    "        sim_best_rsrs,\n",
    "        test_aas, \n",
    "        test_wsrs, \n",
    "        test_rsrs,\n",
    "        train_aas, \n",
    "        train_wsrs,\n",
    "        train_rsrs,\n",
    "    ):\n",
    "        sim_aas.append(sim_best_aa)\n",
    "        sim_wsrs.append(sim_best_wsr)\n",
    "        sim_rsrs.append(sim_best_rsr)\n",
    "        human_train_aas.append(np.mean(train_aa))\n",
    "        human_train_wsrs.append(np.mean(train_wsr))\n",
    "        human_train_rsrs.append(np.mean(train_rsr))\n",
    "        human_test_aas.append(np.mean(test_aa))\n",
    "        human_test_wsrs.append(np.mean(test_wsr))\n",
    "        human_test_rsrs.append(np.mean(test_rsr))\n",
    "        human_train_aas_details.append(train_aa)\n",
    "        human_train_wsrs_details.append(train_wsr)\n",
    "        human_train_rsrs_details.append(train_rsr)\n",
    "        human_test_aas_details.append(test_aa)\n",
    "        human_test_wsrs_details.append(test_wsr)\n",
    "        human_test_rsrs_details.append(test_rsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b982def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a CSV file in write mode\n",
    "best_params_file_name = data_dir + \"afterPI_1206_train_test_split_repeats_data_rep500.csv\"\n",
    "\n",
    "# Copy for reproducibility\n",
    "sim_aas_cp = copy.deepcopy(sim_aas)\n",
    "sim_wsrs_cp = copy.deepcopy(sim_wsrs) \n",
    "sim_rsrs_cp = copy.deepcopy(sim_rsrs)\n",
    "human_train_aas_cp = copy.deepcopy(human_train_aas)\n",
    "human_train_wsrs_cp = copy.deepcopy(human_train_wsrs)\n",
    "human_train_rsrs_cp = copy.deepcopy(human_train_rsrs) \n",
    "human_test_aas_cp = copy.deepcopy(human_test_aas)\n",
    "human_test_wsrs_cp = copy.deepcopy(human_test_wsrs)\n",
    "human_test_rsrs_cp = copy.deepcopy(human_test_rsrs)\n",
    "\n",
    "SIM_AAS = 'sim_aas'\n",
    "SIM_WSRS = 'sim_wsrs'\n",
    "SIM_RSRS = 'sim_rsrs'\n",
    "HUM_TRAIN_AAS = 'hum_train_aas'\n",
    "HUM_TRAIN_WSRS = 'hum_train_wsrs'\n",
    "HUM_TRAIN_RSRS = 'hum_train_rsrs'\n",
    "HUM_TEST_AAS = 'hum_test_aas'\n",
    "HUM_TEST_WSRS = 'hum_test_wsrs'\n",
    "HUM_TEST_RSRS = 'hum_test_rsrs'\n",
    "\n",
    "# Write\n",
    "with open(best_params_file_name, \"w\", newline='') as csvfile:\n",
    "    # Initialize the CSV writer\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the headers\n",
    "    headers = [\n",
    "        WEIGHTS,\n",
    "        WALK_FACTORS,\n",
    "        PERCEPTION_FACTORS,\n",
    "        SIM_AAS,\n",
    "        SIM_WSRS,\n",
    "        SIM_RSRS,\n",
    "        HUM_TRAIN_AAS,\n",
    "        HUM_TRAIN_WSRS,\n",
    "        HUM_TRAIN_RSRS,\n",
    "        HUM_TEST_AAS,\n",
    "        HUM_TEST_WSRS,\n",
    "        HUM_TEST_RSRS,\n",
    "    ]\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Write data for each layout\n",
    "    for i, best_param in enumerate(all_best_params):\n",
    "        row = [\n",
    "            best_param[0],  # weights\n",
    "            best_param[1],  # walk_factors\n",
    "            best_param[2],  # perception_factors\n",
    "            sim_aas_cp[i],\n",
    "            sim_wsrs_cp[i],\n",
    "            sim_rsrs_cp[i],\n",
    "            human_train_aas_cp[i],\n",
    "            human_train_wsrs_cp[i],\n",
    "            human_train_rsrs_cp[i],\n",
    "            human_test_aas_cp[i],\n",
    "            human_test_wsrs_cp[i],\n",
    "            human_test_rsrs_cp[i],\n",
    "        ]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce38a7",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d846943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate STD\n",
    "def std(data):\n",
    "    return np.std(data)\n",
    "\n",
    "# Function to adjust y-limit\n",
    "def adjust_ylim(ax, mean, std):\n",
    "#     y_max = max([mean + std for mean, std in zip(means, stds)])\n",
    "    y_max = mean + std\n",
    "    ax.set_ylim(0, y_max * 1.15)  # Adding a bit of margin to the top\n",
    "    \n",
    "# Get data\n",
    "# human test batch data\n",
    "mean_human_test_aas = np.mean(human_test_aas_cp) * 100\n",
    "std_human_test_aas = std(human_test_aas_cp) * 100\n",
    "mean_human_test_wsrs = np.mean(human_test_wsrs_cp) * 100\n",
    "std_human_test_wsrs = std(human_test_wsrs_cp) * 100\n",
    "mean_human_test_rsrs = np.mean(human_test_rsrs_cp) * 100\n",
    "std_human_test_rsrs = std(human_test_rsrs_cp) * 100\n",
    "# parameter inferenced batch data\n",
    "mean_sim_aas = np.mean(sim_aas_cp) * 100\n",
    "std_sim_aas = std(sim_aas_cp) * 100\n",
    "mean_sim_wsrs = np.mean(sim_wsrs_cp) * 100\n",
    "std_sim_wsrs = std(sim_wsrs_cp) * 100\n",
    "mean_sim_rsrs = np.mean(sim_rsrs_cp) * 100\n",
    "std_sim_rsrs = std(sim_rsrs_cp) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02756691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "x = np.array([0.5])\n",
    "width = 0.2\n",
    "\n",
    "def plot_bars(mean_human_test, mean_sim, std_human_test, std_sim, ylabel_text, savefig_name, has_legend=True):\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    rects1 = ax.bar(x - width/2, mean_human_test, width, label='Human Data', color='blue', yerr=std_human_test, capsize=10)\n",
    "    rects2 = ax.bar(x + width/2, mean_sim, width, label='Simulated Data', color='green', yerr=std_sim_aas, capsize=10)\n",
    "    \n",
    "    for i, (rect1, rect2) in enumerate(zip(rects1, rects2)):\n",
    "        height1 = rect1.get_height()\n",
    "        height2 = rect2.get_height()\n",
    "        std1 = std_human_test\n",
    "        std2 = std_sim\n",
    "\n",
    "        ax.annotate(f\"{height1:.2f}\\n({std1:.2f})\", \n",
    "                   (rect1.get_x() + rect1.get_width() / 2., height1 + std1 + 0.05),\n",
    "                   ha='center', va='bottom')\n",
    "        ax.annotate(f\"{height2:.2f}\\n({std2:.2f})\", \n",
    "                   (rect2.get_x() + rect2.get_width() / 2., height2 + std2 + 0.05),\n",
    "                   ha='center', va='bottom')\n",
    "    \n",
    "    ax.set_ylabel(ylabel_text, fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels('', fontsize=12, fontweight='bold')\n",
    "    ax.tick_params(axis='y', labelsize=14)  # Adjust the fontsize as desired for y-axis\n",
    "    \n",
    "    if has_legend == True:\n",
    "        ax.legend(fontsize=15)\n",
    "    \n",
    "    adjust_ylim(ax, mean_human_test + mean_sim, std_human_test + std_sim)\n",
    "    \n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    \n",
    "    fig.savefig(data_dir + savefig_name, dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04e2311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars(mean_human_test_aas, mean_sim_aas, std_human_test_aas, std_sim_aas, 'Sign Attention Allocation (%)', 'study4attentionallocation.png')\n",
    "plot_bars(mean_human_test_wsrs, mean_sim_wsrs, std_human_test_wsrs, std_sim_wsrs, 'Walking Speed Ratio (%)', 'study4walkingspeedratio.png', has_legend=False)\n",
    "plot_bars(mean_human_test_rsrs, mean_sim_rsrs, std_human_test_rsrs, std_sim_rsrs, 'Reading Speed Ratio (%)', 'study4readingspeedratio.png', has_legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5766616e",
   "metadata": {},
   "source": [
    "### Stastical Analysis: RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cfd57ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE for attention allocation is: 0.1214\n",
      "Average RMSE for walking speed ratio is: 0.1088\n",
      "Average RMSE for reading speed ratio is: 0.3371\n"
     ]
    }
   ],
   "source": [
    "# RMSE computation function\n",
    "def compute_rmse(true_vals, predicted_vals):\n",
    "    return np.sqrt(np.mean((np.array(true_vals) - np.array(predicted_vals)) ** 2))\n",
    "\n",
    "# Compute RMSE for durations and errors for each layout\n",
    "rmse_durations_layouts = {}\n",
    "rmse_errors_layouts = {}\n",
    "\n",
    "rmse_aas = compute_rmse(human_test_aas_cp, sim_aas_cp)\n",
    "rmse_wsrs = compute_rmse(human_test_wsrs_cp, sim_wsrs_cp)\n",
    "rmse_rsrs = compute_rmse(human_test_rsrs_cp, sim_rsrs_cp)\n",
    "\n",
    "# Display results\n",
    "print(f\"Average RMSE for attention allocation is: {rmse_aas:.4f}\")\n",
    "print(f\"Average RMSE for walking speed ratio is: {rmse_wsrs:.4f}\")\n",
    "print(f\"Average RMSE for reading speed ratio is: {rmse_rsrs:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e9741",
   "metadata": {},
   "source": [
    "### Stastical Analysis: Anderson-Darling two-sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acd0e5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention allocation: Anderson_ksampResult(statistic=543.1117478621023, critical_values=array([0.325, 1.226, 1.961, 2.718, 3.752, 4.592, 6.546]), pvalue=0.001), \n",
      "Walking Speed Ratio: Anderson_ksampResult(statistic=62.98806459644165, critical_values=array([0.325, 1.226, 1.961, 2.718, 3.752, 4.592, 6.546]), pvalue=0.001), \n",
      "Reading Speed Ratio: Anderson_ksampResult(statistic=541.0103856701992, critical_values=array([0.325, 1.226, 1.961, 2.718, 3.752, 4.592, 6.546]), pvalue=0.001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\874954781.py:2: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  ad_aas = anderson_ksamp([human_test_aas_cp, sim_aas_cp])\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\874954781.py:3: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  ad_wsrs = anderson_ksamp([human_test_wsrs_cp, sim_wsrs_cp])\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_36232\\874954781.py:4: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  ad_rsrs = anderson_ksamp([human_test_rsrs_cp, sim_rsrs_cp])\n"
     ]
    }
   ],
   "source": [
    "# Performing the Anderson-Darling two-sample test\n",
    "ad_aas = anderson_ksamp([human_test_aas_cp, sim_aas_cp])\n",
    "ad_wsrs = anderson_ksamp([human_test_wsrs_cp, sim_wsrs_cp])\n",
    "ad_rsrs = anderson_ksamp([human_test_rsrs_cp, sim_rsrs_cp])\n",
    "print(f'Attention allocation: {ad_aas}, \\nWalking Speed Ratio: {ad_wsrs}, \\nReading Speed Ratio: {ad_rsrs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2745dde",
   "metadata": {},
   "source": [
    "### Reading Resumption Time Cost (s), Error Rate (%).\n",
    "Done in the neighbor jupyter-notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1e01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-cuda)",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
