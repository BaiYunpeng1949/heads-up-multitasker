{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec82b95b",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71d328b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import anderson_ksamp\n",
    "from ast import literal_eval\n",
    "\n",
    "# Get data source\n",
    "data_dir = 'data_process/12-04/'\n",
    "\n",
    "# Read raw simulated data\n",
    "simulated_raw_data = data_dir + 'simulated_data_aa_wsr_rsr.csv'\n",
    "# Read Human Data\n",
    "human_data = data_dir + 'human_data_aa_wsr_rsr.csv'\n",
    "\n",
    "# Convert to a dataframe\n",
    "df_raw_sim = pd.read_csv(simulated_raw_data)\n",
    "df_human = pd.read_csv(human_data)\n",
    "\n",
    "# Identify the parameters that to be tuned later\n",
    "WEIGHTS = 'weights'             # Ranges from 0-1\n",
    "WALK_FACTORS = 'walk_factors'   # Ranges from 0-1\n",
    "SIGN_FACTORS = 'sign_factors'   # Ranges from 0-1\n",
    "params = {\n",
    "    WEIGHT: None,\n",
    "    WALK_FACTOR: None,\n",
    "    SIGN_FACTOR: None,\n",
    "}\n",
    "# Some other variables from the simulated file\n",
    "STEPS = 'steps'\n",
    "SIGN_READ = 'sign_read'\n",
    "STEP_WISE_WALKING_POSITIONS = 'step_wise_walking_positions'\n",
    "EXP_WALKING_POSITIONS = 'walking_positions'\n",
    "STEP_WISE_WALKING_SPEEDS = 'step_wise_walking_speeds'\n",
    "EXP_WALKING_SPEEDS = 'walking_speeds'\n",
    "WALKING_SPEED_RATIOS = 'walking_speed_ratios'\n",
    "STEP_WISE_ATTENTIONS = 'step_wise_attentions'\n",
    "EXP_ATTENTION = 'attention_allocation'\n",
    "ATTENTION_ON_SIGN = 'attention_on_sign'\n",
    "ATTENTION_ON_OHMD = 'attention_on_ohmd'\n",
    "SIGN_POSITIONS = 'sign_positions'\n",
    "STEP_WISE_READING_RATIOS = 'step_wise_reading_ratios'\n",
    "READING_SPEED_RATIOS = 'reading_speed_ratios'\n",
    "EXP_READING_RATIOS = 'reading_ratios'\n",
    "RECTANGLE_PATH_LENGTH = 'rectangle_path_length'\n",
    "EP_LEN = 'ep_len'\n",
    "\n",
    "SIGN = 'Sign'\n",
    "ZERO_DOT_ONE = 0.1\n",
    "WALK_FACTORS = 'walk_factors'\n",
    "\n",
    "# Determine the metrics\n",
    "ATTENTION_ALLOCATION = 'attention_allocation'\n",
    "WALKING_SPEED_RATIO = 'walking_speed_ratio'\n",
    "READING_SPEED_RATIO = 'reading_speed_ratio'\n",
    "metrics = [ATTENTION_ALLOCATION, WALKING_SPEED_RATIO, READING_SPEED_RATIO]\n",
    "\n",
    "# Parameters that can be pre-defined\n",
    "DEFAULT_WALK_FACTOR = 0.5\n",
    "DEFAULT_SIGN_FACTOR = 0.5\n",
    "\n",
    "# Number of signs in the experiment\n",
    "NUM_SIGN_IN_EXP = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb694665",
   "metadata": {},
   "source": [
    "### Process the Raw Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "45b7992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string representations of lists into actual lists\n",
    "def literal_eval_col(col):\n",
    "    return col.apply(literal_eval)\n",
    "# def literal_eval_col(col):\n",
    "#     return col.apply(lambda x: literal_eval(x) if not pd.isnull(x) else [])\n",
    "\n",
    "# Round values\n",
    "def round_nested_lists(column):\n",
    "    rounded_column = []\n",
    "    for row in column:\n",
    "        if isinstance(row, list):\n",
    "            rounded_row = [round(element, 1) if isinstance(element, float) else element for element in row]\n",
    "            rounded_column.append(rounded_row)\n",
    "        else:\n",
    "            rounded_column.append(row)\n",
    "    return rounded_column\n",
    "\n",
    "# Process raw simulated data - main function - process data line by line\n",
    "def process_raw_simulated_data(df_raw_sim):\n",
    "    # Convert strings to lists in the whole df\n",
    "    df_raw_sim.dropna(how='all', inplace=True)\n",
    "    \n",
    "#     df_raw_sim[STEP_WISE_WALKING_POSITIONS] = literal_eval_col(df_raw_sim[STEP_WISE_WALKING_POSITIONS])\n",
    "#     df_raw_sim[STEP_WISE_WALKING_SPEEDS] = literal_eval_col(df_raw_sim[STEP_WISE_WALKING_SPEEDS])\n",
    "#     df_raw_sim[STEP_WISE_ATTENTIONS] = literal_eval_col(df_raw_sim[STEP_WISE_ATTENTIONS])\n",
    "#     df_raw_sim[SIGN_READ] = literal_eval_col(df_raw_sim[SIGN_READ])\n",
    "#     df_raw_sim[STEP_WISE_READING_RATIOS] = literal_eval_col(df_raw_sim[STEP_WISE_READING_RATIOS])\n",
    "    rectangle_path_length = df_raw_sim.at[1, 'rectangle_path_length']\n",
    "    \n",
    "    #####################################################################\n",
    "    # Get rid of the rows whose len(sign_read) < num_sign_in_exp\n",
    "    df_read_eight_signs = df_raw_sim[df_raw_sim[SIGN_READ].apply(lambda x: len(x) >= NUM_SIGN_IN_EXP)]\n",
    "#     df_read_eight_signs = df_read_eight_signs[df_read_eight_signs[WALK_FACTORS] == DEFAULT_WALK_FACTOR]\n",
    "    \n",
    "    #####################################################################\n",
    "    empty_lists = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    \n",
    "    # Creating a new column initialized with empty lists\n",
    "    df_read_eight_signs[EXP_ATTENTION] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    df_read_eight_signs[EXP_WALKING_SPEEDS] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    df_read_eight_signs[EXP_READING_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    # Iterate over each row\n",
    "    for index, row in df_read_eight_signs.iterrows():\n",
    "        # Find the index where the value in 'step_wise_walking_positions' first exceeds 60\n",
    "        index_exceeding_60 = next((i for i, val in enumerate(row[STEP_WISE_WALKING_POSITIONS]) if val > rectangle_path_length), None)\n",
    "        \n",
    "        # If such an index is found, slice 'step_wise_attention_allocation' up to that index\n",
    "        if index_exceeding_60 is not None:\n",
    "            df_read_eight_signs.at[index, EXP_ATTENTION] = row[STEP_WISE_ATTENTIONS][:index_exceeding_60]\n",
    "            df_read_eight_signs.at[index, EXP_WALKING_SPEEDS] = row[STEP_WISE_WALKING_SPEEDS][:index_exceeding_60]\n",
    "            df_read_eight_signs.at[index, EXP_READING_RATIOS] = row[STEP_WISE_READING_RATIOS][:index_exceeding_60]\n",
    "        else:\n",
    "            # If no value exceeds 60, the column remains an empty list for this row\n",
    "            df_read_eight_signs.at[index, EXP_ATTENTION] = []\n",
    "            df_read_eight_signs.at[index, EXP_WALKING_SPEEDS] = []\n",
    "            df_read_eight_signs.at[index, EXP_READING_RATIOS] = []\n",
    "    \n",
    "    #####################################################################\n",
    "    # Get indexes where the attention is on the sign, which are on the OHMD\n",
    "    # Initialize the new columns with empty lists\n",
    "    df_read_eight_signs[ATTENTION_ON_SIGN] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    df_read_eight_signs[ATTENTION_ON_OHMD] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    # Initialize the new column with empty lists\n",
    "    df_read_eight_signs[READING_SPEED_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    # Iterate over each row\n",
    "    for index, row in df_read_eight_signs.iterrows():\n",
    "        # Lists to store attention data\n",
    "        attention_on_sign = []\n",
    "        attention_on_ohmd = []\n",
    "        reading_speed_ratios = []\n",
    "\n",
    "        # Check each item in the 'EXP_ATTENTION' list\n",
    "        for i, attention_item in enumerate(row[EXP_ATTENTION]):\n",
    "            if attention_item != 'Sign':\n",
    "                attention_on_ohmd.append(attention_item)\n",
    "                # Append the corresponding item from 'EXP_READING_RATIOS'\n",
    "                reading_speed_ratios.append(row[EXP_READING_RATIOS][i])\n",
    "            else:\n",
    "                attention_on_sign.append(attention_item)         \n",
    "\n",
    "        # Assign the lists to the new columns\n",
    "        df_read_eight_signs.at[index, ATTENTION_ON_SIGN] = attention_on_sign\n",
    "        df_read_eight_signs.at[index, ATTENTION_ON_OHMD] = attention_on_ohmd\n",
    "        df_read_eight_signs.at[index, READING_SPEED_RATIOS] = reading_speed_ratios\n",
    "        \n",
    "    #####################################################################\n",
    "    df_read_eight_signs[WALKING_SPEED_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
    "    # Iterate over each row\n",
    "    for index, row in df_read_eight_signs.iterrows():\n",
    "        # Filter walking speeds greater than 0.1\n",
    "        walking_speeds_above_threshold = [speed for speed in row[EXP_WALKING_SPEEDS] if speed > ZERO_DOT_ONE]\n",
    "        # Assign the filtered speeds to the new column\n",
    "        df_read_eight_signs.at[index, WALKING_SPEED_RATIOS] = walking_speeds_above_threshold\n",
    "    \n",
    "    #####################################################################\n",
    "    df_read_eight_signs[ATTENTION_ALLOCATION] = 0\n",
    "    df_read_eight_signs[WALKING_SPEED_RATIO] = 0\n",
    "    df_read_eight_signs[READING_SPEED_RATIO] = 0\n",
    "    \n",
    "    # Iterate over each row to calculate the ratios\n",
    "    for index, row in df_read_eight_signs.iterrows():\n",
    "        # Calculate the attention allocation ratio\n",
    "        if len(row[ATTENTION_ON_OHMD]) > 0:\n",
    "            df_read_eight_signs.at[index, ATTENTION_ALLOCATION] = len(row[ATTENTION_ON_SIGN]) / (len(row[ATTENTION_ON_OHMD]) + len(row[ATTENTION_ON_SIGN]))\n",
    "        else:\n",
    "            df_read_eight_signs.at[index, ATTENTION_ALLOCATION] = float('inf')  # or some other value to indicate undefined\n",
    "\n",
    "        # Calculate the walking speed ratio (average)\n",
    "        if row[WALKING_SPEED_RATIOS]:\n",
    "            df_read_eight_signs.at[index, WALKING_SPEED_RATIO] = sum(row[WALKING_SPEED_RATIOS]) / len(row[WALKING_SPEED_RATIOS])\n",
    "\n",
    "        # Calculate the reading speed ratio (average)\n",
    "        if row[READING_SPEED_RATIOS]:\n",
    "            df_read_eight_signs.at[index, READING_SPEED_RATIO] = sum(row[READING_SPEED_RATIOS]) / len(row[READING_SPEED_RATIOS])\n",
    "        \n",
    "    #####################################################################\n",
    "    # Write the DataFrame to a CSV file\n",
    "    df_read_eight_signs.to_csv(data_dir+'processed_simulated_data.csv', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f7194f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_80028\\3408170741.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[EXP_ATTENTION] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_80028\\3408170741.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[EXP_WALKING_SPEEDS] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_80028\\3408170741.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[EXP_READING_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_80028\\3408170741.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[ATTENTION_ON_SIGN] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_80028\\3408170741.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[ATTENTION_ON_OHMD] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_80028\\3408170741.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[READING_SPEED_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_80028\\3408170741.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[WALKING_SPEED_RATIOS] = [[] for _ in range(len(df_read_eight_signs))]\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_80028\\3408170741.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[ATTENTION_ALLOCATION] = 0\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_80028\\3408170741.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[WALKING_SPEED_RATIO] = 0\n",
      "C:\\Users\\91584\\AppData\\Local\\Temp\\ipykernel_80028\\3408170741.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_read_eight_signs[READING_SPEED_RATIO] = 0\n"
     ]
    }
   ],
   "source": [
    "process_raw_simulated_data(df_raw_sim=df_raw_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12fd737",
   "metadata": {},
   "source": [
    "### Parameter Inference: Attention Allocation (s), Walking Speed Ratio (%), Reading Speed Ratio (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize a list\n",
    "def normalize(lst):\n",
    "    min_val = min(lst)\n",
    "    max_val = max(lst)\n",
    "    if min_val == max_val:  # Avoid division by zero\n",
    "        return [0.5 for _ in lst]  # Return 0.5 (middle) if all values are same\n",
    "    return [(x - min_val) / (max_val - min_val) for x in lst]\n",
    "\n",
    "# Define the cost function\n",
    "def compute_cost(sim_data, human_data):\n",
    "    return sum(abs(sim - human) for sim, human in zip(sim_data, human_data))\n",
    "\n",
    "# Find the best parameter\n",
    "def find_best_params(df_sim, mean_train_aa, mean_train_wsr, mean_train_rsr):\n",
    "#     # Filter by adding constraints\n",
    "#     df_sim = df_sim[df_sim['xxxx'] == xxxx]\n",
    "    \n",
    "    unique_params = df_sim[['layout', 'steps', 'error']].drop_duplicates()\n",
    "    min_cost = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    for index, row in unique_params.iterrows():\n",
    "        filtered_df = df_sim[\n",
    "            (df_sim[WEIGHTS] == row[WEGHTS]) &\n",
    "            (df_sim[WALK_FACTOR] == row[WALK_FACTOR])\n",
    "        ]\n",
    "        \n",
    "        # Get simulated data\n",
    "        sim_aa = filtered_df[ATTENTION_ALLOCATION].values[0]\n",
    "        sim_wsr = filtered_df[WALKING_SPEED_RATIOS].values[0]\n",
    "        sim_rsr = filtered_df[READING_SPEED_RATIOS].values[0]\n",
    "        \n",
    "        # Get human data\n",
    "        human_aa = \n",
    "        human_wsr\n",
    "        human_rsr\n",
    "        \n",
    "        cost_aa = compute_cost(normalize(sim_aa), normalize(human_aa))\n",
    "        cost_wsr = compute_cost(normalize(sim_wsr), normalize(human_wsr))\n",
    "        cost_rsr = compute_cost(normalize(sim_rsr), normalize(human_rsr))\n",
    "        \n",
    "        total_cost = cost_aa + cost_wsr + cost_rsr\n",
    "\n",
    "        if total_cost < min_cost:\n",
    "            min_cost = total_cost\n",
    "            best_params = row\n",
    "    \n",
    "    # Given the best parameters and the dataframe, return the simulated results\n",
    "    sim_aa_best = []\n",
    "    sim_wsr_best = []\n",
    "    sim_rsr_best = []\n",
    "    \n",
    "    # Extract the simulated steps and error for each layout based on best_params\n",
    "    filtered_df = df_sim[\n",
    "        (df_sim[WEIGHTS] == best_params[WEIGHTS]) &\n",
    "        (df_sim[WALK_FACTORS] == best_params[WALK_FACTORS])\n",
    "    ]\n",
    "\n",
    "    sim_aa_best.append(filtered_df[ATTENTION_ALLOCATION].values[0])\n",
    "    sim_wsr_best.append(filtered_df[WALKING_SPEED_RATIO].values[0])\n",
    "    sim_rsr_best.append(filtered_df[READING_SPEED_RATIO].values[0])\n",
    "\n",
    "    return best_params, min_cost, sim_steps_best, sim_errors_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded1923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_iterations = 500\n",
    "all_costs = []\n",
    "all_best_params = []\n",
    "\n",
    "# # Lists to store sim-to-real mapping ratios for each iteration\n",
    "# sim_to_real_ratios_duration = []\n",
    "# sim_to_real_ratios_error = []\n",
    "\n",
    "# Initialize dictionaries for storing results\n",
    "simulated_durations = {'L100': []}\n",
    "simulated_errors = {'L100': []}\n",
    "human_train_durations = {'L100': []}\n",
    "human_train_errors = {'L100': []}\n",
    "human_test_durations = {'L100': []}\n",
    "human_test_errors = {'L100': []}\n",
    "human_train_durations_details = {'L100': []}  # Collect detailed data in each iterations, not aggregated\n",
    "human_train_errors_details = {'L100': []}\n",
    "human_test_durations_details = {'L100': []}\n",
    "human_test_errors_details = {'L100': []}\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Number of participants\n",
    "    num_participants = len(human_duration_data[0])\n",
    "\n",
    "    # Generate list of indices based on participants\n",
    "    indices = list(range(num_participants))\n",
    "\n",
    "    # Split indices to ensure consistency\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=0.5, random_state=i)  \n",
    "    # using i as the seed for reproducibility\n",
    "\n",
    "    # Use these indices to split the human data consistently across participants\n",
    "    def split_data_based_on_indices(data, train_indices, test_indices):\n",
    "        train_set = [data[i] for i in train_indices]\n",
    "        test_set = [data[i] for i in test_indices]\n",
    "        return train_set, test_set\n",
    "\n",
    "    # Split human duration data\n",
    "    train_duration = [split_data_based_on_indices(condition, train_indices, test_indices) for condition in human_duration_data]\n",
    "    train_duration = list(zip(*train_duration))[0]  # Extracting the training data\n",
    "\n",
    "    test_duration = [split_data_based_on_indices(condition, train_indices, test_indices) for condition in human_duration_data]\n",
    "    test_duration = list(zip(*test_duration))[1]  # Extracting the test data\n",
    "\n",
    "    # Split human error data\n",
    "    train_error = [split_data_based_on_indices(condition, train_indices, test_indices) for condition in human_error_data]\n",
    "    train_error = list(zip(*train_error))[0]  # Extracting the training data\n",
    "\n",
    "    test_error = [split_data_based_on_indices(condition, train_indices, test_indices) for condition in human_error_data]\n",
    "    test_error = list(zip(*test_error))[1]  # Extracting the test data\n",
    "\n",
    "    # Compute mean for the training and test sets\n",
    "    mean_train_duration = [np.mean(data) for data in train_duration]\n",
    "    mean_train_error = [np.mean(data) for data in train_error]\n",
    "    mean_test_duration = [np.mean(data) for data in test_duration]\n",
    "    mean_test_error = [np.mean(data) for data in test_error]\n",
    "\n",
    "    # Using the function to find the best parameters\n",
    "    best_params, _, sim_durations, sim_errors = find_best_params(df_simulations, mean_train_duration, mean_train_error)\n",
    "    all_best_params.append(best_params)\n",
    "    \n",
    "    # Get sim to real mapping ratios for duration and error metrics respectively\n",
    "    # Compute sim-to-real ratio for the current iteration\n",
    "    sim_to_real_ratio_duration = sum(mean_train_duration) / sum(sim_durations)\n",
    "    sim_to_real_ratio_error = sum(mean_train_error) / sum(sim_errors)\n",
    "    \n",
    "    # Store the computed ratios\n",
    "    sim_to_real_ratios_duration.append(sim_to_real_ratio_duration)\n",
    "    sim_to_real_ratios_error.append(sim_to_real_ratio_error)\n",
    "    \n",
    "    for label, sd, se, ted, tee, trd, tre in zip(\n",
    "        ['L100'], \n",
    "        sim_durations, \n",
    "        sim_errors, \n",
    "        test_duration, \n",
    "        test_error, \n",
    "        train_duration, \n",
    "        train_error,\n",
    "    ):\n",
    "        simulated_durations[label].append(sd)\n",
    "        simulated_errors[label].append(se)\n",
    "        human_train_durations[label].append(np.mean(trd))\n",
    "        human_train_errors[label].append(np.mean(tre))\n",
    "        human_test_durations[label].append(np.mean(ted))\n",
    "        human_test_errors[label].append(np.mean(tee))\n",
    "        human_train_durations_details[label].append(trd)\n",
    "        human_train_errors_details[label].append(tre)\n",
    "        human_test_durations_details[label].append(ted)\n",
    "        human_test_errors_details[label].append(tee)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2745dde",
   "metadata": {},
   "source": [
    "### Reading Resumption Time Cost (s), Error Rate (%).\n",
    "Done in the neighbor jupyter-notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1e01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-cuda)",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
