simulator_name: 'huc'

rl:
  mode: test    # Select from: train, continual_train, test, debug (check_env many times for the baseline).

  train:
    total_timesteps: 200000000
    checkpoints_folder_name: 'checkpoints_0720_mdp_resume_read_200m'
    num_workers: 10   # Smaller than the laptop's number of processes: 16 - should not be the maximum capacity of the processors, otherwise the local memory will overflow.
    num_steps: 5000   # TODO do not change this parameter
    batch_size: 500   # We recommend using a `batch_size` that is a factor of `n_steps * n_envs`
    ent_coef: 0.03    # Entropy coefficient
    n_epochs: 10       # Number of epochs
    clip_range: 0.2   # Clipping range
    clip_range_vf: None   # Clipping range for the value function
    learning_rate:   # Learning rate
      initial_value: 1e-5
      min_value: 1e-7
      threshold: 0.8
    device: 'cuda'     # 'cuda' for default
    save_freq: 5000000  # Save a checkpoint every 0.5 million steps

  test:
    num_episodes: 1
    layout_name: ''    # Choose from 'interline-spacing-100', 'bottom-center', 'middle-right'
    loaded_model_name: 'rl_model_30000000_steps'
    continual_logs_name: 'PPO_201'
    grid_search_perturbation:
      enable: False
      dwell_steps: [[0.2, 0.5], 0.01]
      amp_tuning_factor: [[0, 1], 0.01]
      perturbation_amp_noise_scale: [[0, 0.015], 0.001]
    grid_search_selection:
      enable: False
      init_delta_t: [[1, 5], 0.2]
      init_sigma_position_memory: [[0.5, 10], 0.5]
      weight_memory_decay: [[0.1, 1], 0.05]
      spatial_dist_coeff: [[0.1, 10], 0.5]
      layouts: ['L0', 'L50', 'L100']
      num_episodes: 100

mj_env:
  xml: ''
  width: 80
  height: 80
