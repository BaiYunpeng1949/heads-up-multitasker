simulator_name: 'huc'

rl:
  mode: test    # Select from: train, continual_train, test, debug (check_env many times for the baseline), and interact.

  train:
    total_timesteps: 100000000
    checkpoints_folder_name: 'checkpoints_0619_mobile_reading_100m'
    num_workers: 10   # Smaller than the laptop's number of processes: 16 - should not be the maximum capacity of the processors, otherwise the local memory will overflow.
    num_steps: 5000   # TODO do not change this parameter
    batch_size: 500   # We recommend using a `batch_size` that is a factor of `n_steps * n_envs`
    ent_coef: 0.03    # Entropy coefficient
    n_epochs: 10       # Number of epochs
    clip_range: 0.2   # Clipping range
    clip_range_vf: None   # Clipping range for the value function
    learning_rate:   # Learning rate
      initial_value: 1e-5
      min_value: 1e-7
      threshold: 0.8
    device: 'cuda'     # 'cuda' for default
    save_freq: 50000  # Save a checkpoint every 0.5 million steps

  test:
    num_episodes: 1
    layout_name: ''    # Choose from 'interline-spacing-100', 'bottom-center', 'middle-right'
    loaded_model_name: 'rl_model_40000000_steps'
    continual_logs_name: 'PPO_174'

mj_env:
  xml: ''
  width: 80
  height: 80
